{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO79SNpICyF8BpddHrcV0I8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZerXXX0/sales-prediction/blob/main/FTTransformer_MLQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "_aNvUklR5gyB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H8msW7r24-lU"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('https://raw.githubusercontent.com/ZerXXX0/sales-prediction/refs/heads/main/dataset/train_final.csv')\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/ZerXXX0/sales-prediction/refs/heads/main/dataset/test_final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Preprocessing ===\n",
        "drop_cols = ['Unnamed: 0', 'TransactionID', 'MemberID']\n",
        "train_df_clean = train_df.drop(columns=drop_cols)\n",
        "\n",
        "X = train_df_clean.drop(columns=['next_buy'])\n",
        "y = train_df_clean['next_buy']\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)"
      ],
      "metadata": {
        "id": "lXH0Q-j_5jH_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "M61o7MC75vYj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=512, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=512)"
      ],
      "metadata": {
        "id": "GGoe1CQU6CnL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === FT-Transformer Model ===\n",
        "class FTTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, dim=64, depth=3, heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dropout=dropout, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        x = self.embedding(x).unsqueeze(1)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = self.transformer(x)\n",
        "        return self.head(x[:, 0])\n"
      ],
      "metadata": {
        "id": "L6YDOUyX6G3K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Training Loop ===\n",
        "model = FTTransformer(input_dim=X_train.shape[1])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "IsIdzGC46LCZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=50, save_path=\"best_ft_transformer.pth\"):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                preds = model(xb)\n",
        "                predicted = torch.argmax(preds, dim=1)\n",
        "                correct += (predicted == yb).sum().item()\n",
        "                total += yb.size(0)\n",
        "        acc = correct / total * 100\n",
        "\n",
        "        # Save the best model\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"✅ Saved new best model (epoch {epoch+1}, val acc: {acc:.2f}%)\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={total_loss:.4f}, Val Acc={acc:.2f}%\")"
      ],
      "metadata": {
        "id": "JTBAv5v76N24"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHyGegJY6e00",
        "outputId": "1155e16e-1106-444a-ff57-965e0f19da49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model (epoch 1, val acc: 83.62%)\n",
            "Epoch 1: Train Loss=75.3570, Val Acc=83.62%\n",
            "✅ Saved new best model (epoch 2, val acc: 83.90%)\n",
            "Epoch 2: Train Loss=70.6215, Val Acc=83.90%\n",
            "Epoch 3: Train Loss=69.8157, Val Acc=83.73%\n",
            "Epoch 4: Train Loss=69.3489, Val Acc=83.37%\n",
            "Epoch 5: Train Loss=69.2305, Val Acc=83.75%\n",
            "Epoch 6: Train Loss=68.8645, Val Acc=83.88%\n",
            "✅ Saved new best model (epoch 7, val acc: 84.07%)\n",
            "Epoch 7: Train Loss=68.8890, Val Acc=84.07%\n",
            "Epoch 8: Train Loss=68.6198, Val Acc=83.45%\n",
            "Epoch 9: Train Loss=68.5532, Val Acc=83.96%\n",
            "Epoch 10: Train Loss=68.5617, Val Acc=83.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-create the model\n",
        "model = FTTransformer(input_dim=X_train.shape[1])\n",
        "model.load_state_dict(torch.load(\"best_ft_transformer.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOWEGq9r6XiQ",
        "outputId": "6a538531-78f0-40bc-fe56-383ef3d35765"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FTTransformer(\n",
              "  (embedding): Linear(in_features=8, out_features=64, bias=True)\n",
              "  (transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Sequential(\n",
              "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Linear(in_features=64, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Preprocess test set ===\n",
        "member_ids = test_df[\"MemberID\"]  # Save MemberID before dropping\n",
        "\n",
        "drop_cols = ['Unnamed: 0', 'TransactionID', 'MemberID']\n",
        "test_df_clean = test_df.drop(columns=drop_cols)\n",
        "\n",
        "# Use the same preprocessing steps\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_test_imputed = imputer.fit_transform(test_df_clean)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_test_scaled = scaler.fit_transform(X_test_imputed)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "FTlFrMH0660h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Predict ===\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test_tensor)\n",
        "    predicted_classes = torch.argmax(preds, dim=1).numpy()\n",
        "\n",
        "# === Export predictions with MemberID ===\n",
        "output = pd.DataFrame({\n",
        "    \"MemberID\": member_ids,\n",
        "    \"next_buy_predicted\": predicted_classes\n",
        "})\n",
        "\n",
        "output.to_csv(\"ft_transformer_predictions.csv\", index=False)\n",
        "print(\"✅ Predictions saved to ft_transformer_predictions.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQvzr8Ox7Vd7",
        "outputId": "23f88d1f-7026-481c-d33b-faa5ff53bb7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Predictions saved to ft_transformer_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.read_csv(\"/content/ft_transformer_predictions.csv\")"
      ],
      "metadata": {
        "id": "BR5-U1OG9bDT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: rename a column\n",
        "\n",
        "submission_df = submission_df.rename(columns={\"next_buy_predicted\": \"next_buy\"})\n",
        "submission_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzMvyVRG9eYy",
        "outputId": "ebca0828-bbd0-4898-83bc-551aa13f330f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21098 entries, 0 to 21097\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   MemberID  21098 non-null  object\n",
            " 1   next_buy  21098 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 329.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df = pd.read_csv(\"https://raw.githubusercontent.com/ZerXXX0/sales-prediction/refs/heads/main/dataset/sample_submission.csv\")\n",
        "# First, create a new dataframe from submission_df with duplicate MemberIDs removed.\n",
        "# We keep the 'last' entry for each member.\n",
        "submission_df_unique = submission_df.drop_duplicates(subset=['MemberID'], keep='last')\n",
        "\n",
        "# Now, create the lookup map from this de-duplicated dataframe.\n",
        "# This will succeed because the 'MemberID' index is now unique.\n",
        "next_buy_lookup = submission_df_unique.set_index('MemberID')['next_buy']\n",
        "\n",
        "# Proceed with the map operation as before. This will now work correctly.\n",
        "submit_df['next_buy'] = submit_df['MemberID'].map(next_buy_lookup)"
      ],
      "metadata": {
        "id": "hfu8ETIZ9CQq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeuGBDwD9EnY",
        "outputId": "a835f01d-3747-4169-daf4-ec8b69d0bd68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6381 entries, 0 to 6380\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   MemberID  6381 non-null   object\n",
            " 1   next_buy  6381 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 99.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df.to_csv('submission_FTTransformer.csv', index=False)"
      ],
      "metadata": {
        "id": "SMxM3dgx9nRB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0xX8kUj9sqC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}